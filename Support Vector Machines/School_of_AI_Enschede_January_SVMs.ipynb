{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "School of AI Enschede January SVMs",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OnnG9fFj47A",
        "colab_type": "text"
      },
      "source": [
        "# Intro to Scikit Learn and SVMs\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/wilcobonestroo/schoolofai/blob/master/Support%20Vector%20Machines/School_of_AI_Enschede_January_SVMs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR6K3a6an9NJ",
        "colab_type": "text"
      },
      "source": [
        "# Scikit Learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so8AqOLTrTKZ",
        "colab_type": "text"
      },
      "source": [
        "First we are going to load the iris dataset that is shipped with Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UljzatprUGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqVKAzsrsKdF",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"right\" width=\"200\" alt=\"Iris (source: Wikipedia: https://en.wikipedia.org/wiki/Iris_flower_data_set\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/1024px-Iris_versicolor_3.jpg\">\n",
        "\n",
        "There are many ways to get an idea of how the dataset is structured. In this environment, you can select the code block above and hover with your mouse pointer over the iris. Try this, to see the result.\n",
        "\n",
        "We can also print the contents with the following statement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq6Kb5euoHjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(iris)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcmjg1IRtBky",
        "colab_type": "text"
      },
      "source": [
        "To clear the output, use the button to the left of the code (below the play button). The above statement shows that there is a textual **description** in the .DESCR member. The following statement prints that description:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diZnPmmVtSuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(iris.DESCR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QKAzDPviGcj",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machines (SVMs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd50MUeEiObp",
        "colab_type": "text"
      },
      "source": [
        "First we are going to prepare our dataset. To make it easy to visualize we are going to work with only 2 dimensions of the set. We use column 2 and 3 (0-based, so it is column 3 and 4), petal length and petal width. \n",
        "\n",
        "`X` denotes data that is observed at training and prediction time, used as independent variables in learning. The notation is uppercase to denote that it is ordinarily a matrix.\n",
        "\n",
        "`y` denotes data that may be observed at training time as the dependent variable in learning, but which is unavailable at prediction time, and is usually the target of prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXrKqOMKiYjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = iris[\"data\"][:, (2, 3)] # : means beginning to end, (2, 3) means take only columns 2 and 3 (0-based counting)\n",
        "y = iris[\"target\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED9yTEDMT7sL",
        "colab_type": "text"
      },
      "source": [
        "To check if X and y are as expected, we can inspect them with print(X), or simply X. With len(X), you can check how many samples are in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R7bjOTBT4O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "301gSddytX2H",
        "colab_type": "text"
      },
      "source": [
        "We are goning to use SVM as a binary classifier. As there are three classes in the dataset, we or going to throw a part away. We only use the Iris Setosa (y=0) and Iris Versicolor (y=1) data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LJXkwCmkQF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "setosa_or_versicolor = (y == 0) | (y == 1)\n",
        "X = X[setosa_or_versicolor]\n",
        "y = y[setosa_or_versicolor]\n",
        "len(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouPMnKBaohd8",
        "colab_type": "text"
      },
      "source": [
        "Lets visualize the data we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHind3zCoq7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"ro\" , label=\"Setosa\") # plot column 0 on the X axis, 1 on the Y axis. bo means blue circles\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bo\", label=\"Versicolor\")\n",
        "plt.legend()\n",
        "plt.axis([0.5, 5.5, 0, 2])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYMQzSUUktpT",
        "colab_type": "text"
      },
      "source": [
        "Now, we are going to train the SVM to perform classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A-iD2zpksVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))\n",
        "svm_clf.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFbbARSpviOJ",
        "colab_type": "text"
      },
      "source": [
        "To visualize the SVM, we have a custom function to draw the decision line and the \"gutters\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9hc2lK3vsNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# This function makes the \"clean\" plot\n",
        "def plot_svc_clean(svm_clf, xmin, xmax):\n",
        "    # First, get the w and b parameters out of the SMV classifier svm_clf\n",
        "    w = svm_clf.coef_[0]\n",
        "    b = svm_clf.intercept_[0]\n",
        "\n",
        "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
        "    # => x1 = -w0/w1 * x0 - b/w1\n",
        "    x0 = np.linspace(xmin, xmax, 200)\n",
        "    decision_boundary = -w[0]/w[1] * x0 - b/w[1]\n",
        "\n",
        "    margin = 1/w[1]\n",
        "    gutter_up = decision_boundary + margin\n",
        "    gutter_down = decision_boundary - margin\n",
        "\n",
        "    svs = svm_clf.support_vectors_\n",
        "    plt.scatter(svs[:, 0], svs[:, 1], s=360)  # draw the \"support vectors\"\n",
        "\n",
        "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2)\n",
        "    plt.plot(x0, gutter_up, \"r--\", linewidth=2)\n",
        "    plt.plot(x0, gutter_down, \"r--\", linewidth=2)\n",
        "\n",
        "# This function makes the \"colored\" plot with the classes\n",
        "def plot_svc_classes(svm_clf, X, y, x_min, x_max, y_min, y_max):\n",
        "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"ro\", label=\"Setosa\") # plot column 0 on the X axis, 1 on the Y axis. bo means blue circles\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bo\", label=\"Versicolor\")\n",
        "\n",
        "    plt.xticks = False\n",
        "\n",
        "    #plt.scatter(svm_clf.support_vectors_[:, 0], svm_clf.support_vectors_[:, 1], s=100, facecolors='none', zorder=10, edgecolors='k')\n",
        "    #plt.scatter(Xo[:, 0], Xo[:, 1], c=yo, zorder=10, cmap=plt.cm.Paired, edgecolors='k')\n",
        "\n",
        "    XX, YY = np.mgrid[x_min:x_max:800j, y_min:y_max:400j]\n",
        "    Z = svm_clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
        "\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(XX.shape)\n",
        "    #plt.figsize=(xmax-xmin, ymax-ymin)\n",
        "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
        "\n",
        "    # Decision line\n",
        "    plt.contour(XX, YY, Z, colors=['r', 'k', 'r'], linestyles=['--', '-', '--'], levels=[-1, 0, 1])\n",
        "\n",
        "    # Draw the support vectors\n",
        "    svs = svm_clf.support_vectors_\n",
        "    plt.scatter(svs[:, 0], svs[:, 1], s=360)  # draw the \"support vectors\"  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeBoxciewCXr",
        "colab_type": "text"
      },
      "source": [
        "The SVM can now be plotted together with the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQGMaOjOwG-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_svc_clean(svm_clf, 0, 5.5)\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bo\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"ro\")\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.axis([0, 5.5, 0, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_XLWGAqEFU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_svc_classes(svm_clf, X, y, 0.5, 5.5, 0, 2)\n",
        "#plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bo\")\n",
        "#plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"ro\")\n",
        "plt.xlabel(\"Petal length\", fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlcY5rTJxsUm",
        "colab_type": "text"
      },
      "source": [
        "# SVMs with more tricky data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdUhvUg8x0PW",
        "colab_type": "text"
      },
      "source": [
        "The previous examples had extremely nice data, as it was \"linear seperable\". We are now going to look at more \"difficult\" data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R31g_YwqypPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take X and add one sample at 3.4, 1.3 of class y=0\n",
        "Xo = np.append(X, [[3.0, 1.3]], axis=0)\n",
        "yo = np.append(y, [0])\n",
        "\n",
        "# Plet the result\n",
        "plt.plot(Xo[:, 0][yo==0], Xo[:, 1][yo==0], \"ro\" , label=\"Setosa\") # plot column 0 on the X axis, 1 on the Y axis. bo means blue circles\n",
        "plt.plot(Xo[:, 0][yo==1], Xo[:, 1][yo==1], \"bo\", label=\"Versicolor\")\n",
        "plt.legend()\n",
        "plt.axis([0.5, 5.5, 0, 2])\n",
        "\n",
        "#X_outliers = np.array([[3.4, 1.3], [3.2, 0.8]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7oRB2nj3eSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_clf = SVC(kernel=\"linear\", C=1000)\n",
        "svm_clf.fit(Xo, yo)\n",
        "\n",
        "plot_svc_classes(svm_clf, Xo, yo, 0.5, 5.5, 0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cge6_dHt7IdM",
        "colab_type": "text"
      },
      "source": [
        "In the example above, you can try different C values to see what happens. Try 0.1, 1, 10, 1000. Which one do you think generalizes best?\n",
        "\n",
        "We can also use different \"kernels\". Below we use a polynomial kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So2MFVFm_5b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_clf = SVC(kernel=\"poly\", C=10000, degree=3)\n",
        "svm_clf.fit(Xo, yo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcNku3UXBMkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_svc_classes(svm_clf, Xo, yo, 0.5, 5.5, 0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkeYvzqJLbTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now add tho extra points, one for each class\n",
        "Xo = np.append(X, [[3.0, 1.3], [3.0, 1.8]], axis=0)\n",
        "yo = np.append(y, [0, 1])\n",
        "\n",
        "svm_clf = SVC(kernel=\"poly\", C=10000, degree=4, gamma=\"auto\")\n",
        "svm_clf.fit(Xo, yo)\n",
        "plot_svc_classes(svm_clf, Xo, yo, 0, 5.5, 0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfCOZpUsrsqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now add tho extra points, one for each class\n",
        "Xo = np.append(X, [[3.0, 1.3], [3.0, 1.8]], axis=0)\n",
        "yo = np.append(y, [0, 1])\n",
        "\n",
        "svm_clf = SVC(kernel=\"rbf\", C=10, gamma=\"auto\")\n",
        "svm_clf.fit(Xo, yo)\n",
        "plot_svc_classes(svm_clf, Xo, yo, 0, 5.5, 0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42v2iwttsPoO",
        "colab_type": "text"
      },
      "source": [
        "In the examples above, you can try different values for C and for degree. To see all options for the SVM you can have a look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2d0azpSkDuk",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "<img align=\"right\" alt=\"Book cover Hands-On Machine Learning with Scikit-Learn & TensorFlow\" src=\"http://akamaicovers.oreilly.com/images/9781491962282/cat.gif\">\n",
        "\n",
        "This material is based on the book Hands-On Machine Learning with\n",
        "Scikit-Learn and TensorFlow by Aurélien Géron (O’Reilly) and on the accompanying [Github repository](https://github.com/ageron/handson-ml). To continue on the above examples and to recreate the pictures used in the presentation, go to the repository and to Chapter 5.\n",
        "\n",
        "Moreover, the [Tutorials](https://scikit-learn.org/stable/tutorial/index.html) and other documentation from the Scikit Learn website were used as inspiration for the visualisation of the SVMs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xr9GHakuIzB",
        "colab_type": "text"
      },
      "source": [
        "This Notebook was created by Wilco Bonestroo, w.j.bonestroo@saxion.nl, https://www.linkedin.com/in/bonestroo/ for the School of AI session on January 9 at Saxion University of Applied Sciences in Enschede, the Netherlands."
      ]
    }
  ]
}